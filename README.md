# CrawlerDesafio
crawler inicial
 
 O proposito dele é:
 
  1. Abrir uma página do Chrome
  2. Entrar no site TripAdvisor
  3. Clica em aceitar os Cookies
  4. Clicar na barra de pesquisa e escreve "Congresso Nacional - Brasília"
  5. Escolher a terceira opção que aparecer
  6. Vai carregar a página referente a opção
  7. E vai coletar os dados da avalição e do número de avaliações que aquele lugar possuir

# Driver e Bibliotecas
Driver - O driver utilizado é do chrome
  1. Entrar no site https://sites.google.com/chromium.org/driver/downloads
  2. Fazer o download do chromeDriver compativel com a versão do seu google chrome
  3. No windows, coloque o arquivo descompactado na mesma pasta do projeto
  4. No linux, coloque o arquivo descompactado na pasta /bin

Bibliotecas
  1. Abra uma IDE (Vscode, sublime text ou outro)
  2. No terminal da IDE digite "pip install -r requirements.txt" sem as aspas

É extremamente importante que tudo esteja apropriadamente instalado, pois, é fundamental para o funcionamento do web crawler!!!

# Como descobrir a versão do seu google chrome

   1. As instruções são parecidas para outros browsers
   2. No chrome vá nos 3 pontinhos no canto superior direito
   3. Em ajuda, clique no "Sobre o Google Chrome"
    
# Utilizando o crawler
   1. Utilizando uma IDE de sua preferência (Vscode, sublime text ou outro)
   2. Copie e cole todo o código do web_crawler.py na sua IDE
   3. Salve o arquivo como "crawler.py" sem as aspas
   4. e execute.
